{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys, imageio, os\n",
    "sys.path.append(\"/Users/kai/Downloads/graduation/AMFtrack\")\n",
    "from amftrack.util.sys import storage_path\n",
    "from amftrack.ml.width.data_augmentation import data_augmentation, data_preparation\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(storage_path,\"single_focus_-0.3_train\")\n",
    "im_path = os.path.join(path, \"slices.png\")\n",
    "label_path = os.path.join(path, \"labels.npy\")\n",
    "im = imageio.imread(im_path)\n",
    "with open(label_path, \"rb\") as f:\n",
    "    label = np.load(f)\n",
    "label = np.expand_dims(label,1)\n",
    "np.random.seed(0)\n",
    "n_label = np.random.permutation(label.shape[0])\n",
    "print('Data Type: %s' % im.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (im.min(), im.max()))\n",
    "X_train, X_test, y_train, y_test = train_test_split(im,label,test_size=0.4, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(os.path.split(storage_path)[0],\"models\")\n",
    "model_select = os.path.join(model_save_path,\"model_test_CNN\")\n",
    "model = keras.models.load_model(model_select)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call back \n",
    "\n",
    "https://keras.io/guides/writing_your_own_callbacks/\n",
    "\n",
    "https://keras.io/guides/training_with_built_in_methods/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-3 less\"\n",
    "        # \"no longer improving\" being further defined as \"for at least 3 epochs\"\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-3,\n",
    "        patience=3,\n",
    "        verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path for save the model\n",
    "        # The two parameters below mean that we will overwrite the current checkpoint\n",
    "        # if and only if the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath= model_save_path + \"/model_test{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test,y_test),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-tuning\n",
    "\n",
    "https://keras.io/keras_tuner/ \n",
    "\n",
    "https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html\n",
    "\n",
    "https://www.sicara.fr/blog-technique/hyperparameter-tuning-keras-tuner \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/06/create-convolutional-neural-network-model-and-optimize-using-keras-tuner-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    \"\"\"\n",
    "    This is the first model structure for the CNN.\n",
    "    \"\"\"\n",
    "    input = keras.layers.InputLayer(input_shape=(120,1)) # image shape is 120 dimension\n",
    "    scaling = keras.layers.Rescaling(1 / 255)\n",
    "    Conv1 = keras.layers.Conv1D(\n",
    "        filters = 300, kernel_size=12,\n",
    "        strides = 3,   activation=\"relu\",\n",
    "        name    =\"conv1\", activity_regularizer=keras.regularizers.L1L2(l1=1e-5, l2=1e-5))\n",
    "    pool1 = keras.layers.MaxPooling1D(2)\n",
    "    Conv2 = keras.layers.Conv1D(\n",
    "        filters = 320, kernel_size=8,\n",
    "        strides =3,     activation=\"relu\",\n",
    "        name=\"conv2\",  kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))\n",
    "    pool2 = keras.layers.MaxPooling1D(2)\n",
    "    flatten = keras.layers.Flatten()\n",
    "    Dense1 = keras.layers.Dense(units = 340,activation=\"relu\",name=\"dense1\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))\n",
    "    Dense2 = keras.layers.Dense(units = 220,activation=\"relu\",name=\"dense2\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))\n",
    "    output = keras.layers.Dense(units = 1,activation=None,name=\"output\",kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))\n",
    "    model = keras.models.Sequential([input,scaling,Conv1,pool1,Conv2,pool2,flatten,Dense1,Dense2,output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_CNN_basic_hp(hp):\n",
    "    \"\"\"\n",
    "    This is the first model CNN hypertuning.\n",
    "    need to check the input size\n",
    "    need to check dropout layer\n",
    "    need to check L1,L2\n",
    "    need to check the distribution of the data to make sure MAE or MSE\n",
    "    https://blog.yeshuanova.com/2018/02/depthwise-separable-convolution/ \n",
    "    if work need to think about DepthwiseConv1D to make it smaller\n",
    "    \"\"\"\n",
    "    input_size = hp.Fixed(\"input\", 120)\n",
    "    model = keras.Sequential()\n",
    "    # model.add(keras.Input(shape=(input_size, 1))) make sure the input. If it is tensor, you have to put this.\n",
    "    model.add(keras.layers.Rescaling(1 / 255, input_shape=(input_size,1)))\n",
    "    regularize = hp.Float(\"regul\", min_value=1e-5, max_value=1e-1,step=1e-1)\n",
    "    model.add(keras.layers.Conv1D(\n",
    "            filters = hp.Int(f\"filters\",min_value=32,max_value=256,step=32),\n",
    "            kernel_size = hp.Int(f\"kernal_size\",min_value=5,max_value=20,step=5),\n",
    "            activation=\"relu\",\n",
    "            name=f\"conv\",\n",
    "            strides=hp.Int(f\"Strides\",min_value=2,max_value=4,step=1),\n",
    "            activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "    model.add(keras.layers.MaxPooling1D(2))\n",
    "    model.add(keras.layers.Dropout(hp.Float(f\"dropout\", 0.2, 0.5,step=0.1, default=0.2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(\n",
    "            units=hp.Int(\"dense_size\", min_value=8,max_value=256,step=16),activation=\"relu\",\n",
    "            name=f\"dense\",\n",
    "            activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "    model.add(keras.layers.Dropout(hp.Float(f\"dropout\", 0.2, 0.5, step=0.1, default=0.2)))\n",
    "    model.add(keras.layers.Dense(units = 1,activation=None,name=\"output\",activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\",default=1e-3)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"MSE\",\n",
    "        metrics=\"MAE\")\n",
    "    return model\n",
    "hp = kt.HyperParameters()\n",
    "model_tuning = build_model_CNN_basic_hp(hp)\n",
    "model_tuning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_CNN_basic_hp,\n",
    "    objective=\"val_MAE\",\n",
    "    max_trials=50,\n",
    "    seed=11,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape = {X_train.shape}\")\n",
    "print(f\"y_train shape = {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of filter in the CNN\n",
    "layer is {best_hyperparameters.get('filters')} and the optimal learning rate for the optimizer\n",
    "is {best_hyperparameters.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for making a png file for the model\n",
    "keras.utils.plot_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to fix for loop one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_CNN(hp):\n",
    "    \"\"\"\n",
    "    This is the first model CNN hypertuning.\n",
    "    need to check the input size\n",
    "    need to check dropout layer\n",
    "    need to check L1,L2\n",
    "    need to check the distribution of the data to make sure MAE or MSE\n",
    "    https://blog.yeshuanova.com/2018/02/depthwise-separable-convolution/ \n",
    "    if work need to think about DepthwiseConv1D to make it smaller\n",
    "    \"\"\"\n",
    "    input_size = hp.Fixed(\"input\", 120)\n",
    "    model = keras.Sequential()\n",
    "    # model.add(keras.Input(shape=(input_size, 1))) make sure the input. If it is tensor, you have to put this.\n",
    "    model.add(keras.layers.Rescaling(1 / 255, input_shape=(input_size,1)))\n",
    "    regularize = hp.Float(\"regul\", min_value=1e-5, max_value=1e-1,step=1e-1)\n",
    "    for i in range(hp.Int(\"num_conv_layers\", 1, 3,default=2)):\n",
    "        # For convolution layer\n",
    "        model.add(keras.layers.Conv1D(\n",
    "            filters = hp.Int(f\"filters_{i+1}\",min_value=32,max_value=256,step=32),\n",
    "            kernel_size = hp.Int(f\"kernal_size_{i+1}\",min_value=5,max_value=20,step=5),\n",
    "            activation=\"relu\",\n",
    "            name=f\"conv_{i+1}\",\n",
    "            strides=hp.Int(f\"Strides_{i+1}\",min_value=2,max_value=4,step=1),\n",
    "            activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "        # For pooling layer\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        # For drop out layer\n",
    "        # The dropout rate is the fraction of the features that are zeroed out; it’s usually set between 0.2 and 0.5. Francois Chollet book\n",
    "        model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    for j in range(hp.Int(\"num_dense_layers\", 1, 3,default=2)):\n",
    "        # For dense layer\n",
    "        model.add(keras.layers.Dense(\n",
    "            units=hp.Int(\"dense_size\", min_value=8,max_value=256,step=16),activation=\"relu\",\n",
    "            name=f\"dense_{j+1}\",\n",
    "            activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "        model.add(keras.layers.Dropout(hp.Float(f\"dropout_{i+1}\", 0.2, 0.5, step=0.1, default=0.2)))\n",
    "    model.add(keras.layers.Dense(units = 1,activation=None,name=\"output\",activity_regularizer=keras.regularizers.L1(regularize)))\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\",default=1e-3)\n",
    "    # How to choose optimizer: https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        # https://keras.io/api/losses/regression_losses/\n",
    "        # MSLE: target value has a spread of values and when predicting a large value\n",
    "        # MSE: distribution of the target variable is Gaussian\n",
    "        # MAE: mostly Gaussian, but may have outliers\n",
    "        loss=\"mean_absolute_error\",\n",
    "        # https://keras.io/api/metrics/regression_metrics/\n",
    "        # https://towardsdatascience.com/evaluation-metrics-model-selection-in-linear-regression-73c7573208be\n",
    "        # MSE is more sensitive to outliers than MAE.\n",
    "        # MAE Not preferred in cases where outliers are prominent.\n",
    "        metrics=\"mean_squared_error\")\n",
    "    return model\n",
    "hp = kt.HyperParameters()\n",
    "model_tuning = build_model_CNN_basic_hp(hp)\n",
    "model_tuning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_CNN,\n",
    "    objective=\"val_mean_squared_error\",\n",
    "    max_trials=50,\n",
    "    seed=11,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ac19eb75bcf261162520ccd9d5579982c8e385c27a8a3014d1ae342162dd190"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
