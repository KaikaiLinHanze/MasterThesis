{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61a2082-99fd-425e-8b0e-39208a04eb30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 14:34:20.372324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 14:34:20.472233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 14:34:20.472249: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 14:34:20.495236: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 14:34:21.114371: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 14:34:21.114427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 14:34:21.114433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, imageio, os\n",
    "sys.path.append(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project\")\n",
    "from models.model import *\n",
    "from models.data_prepare import *\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecbdaa9-4d76-4f80-a027-137db4eca8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 14:34:24.717824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-09 14:34:24.717846: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-09 14:34:24.717861: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (morricone.ipa.amolf.nl): /proc/driver/nvidia/version does not exist\n",
      "2022-12-09 14:34:24.718086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "HB_only_new = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_only_new_HB_best_model\")\n",
    "BO_only_new = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_only_new_BO_best_model\")\n",
    "HB_vary_lum_focus = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/HB_CNN_MAE_0.87_vary_lum_focus\")\n",
    "BO_vary_lum_focus  = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/BO_CNN_MAE_0.84_vary_lum_focus\")\n",
    "BO_combine = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_best_BO\")\n",
    "HB_combine_old = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_best_HB_1204\")\n",
    "HB_combine_new = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_best_HB_1205\")\n",
    "BO_combine_crop_80 = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_BO_crop_80_best_model\")\n",
    "HB_combine_crop_80 = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_HB_crop_80_best_model\")\n",
    "BO_combine_without_centeral_crop = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_without_centeral_crop_BO_best_model\")\n",
    "HB_combine_without_centeral_crop = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/Kai/Graduation-Project/models/CNN_combine_without_centeral_crop_HB_best_model\")\n",
    "felix = keras.models.load_model(\"/home/ipausers/lin/Desktop/Graduation/AMFtrack/amftrack/ml/models/default_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d29001-f856-42fb-9351-876270d0136f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipausers/lin/Desktop/AMF/AMFtrack/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/ipausers/lin/Desktop/AMF/AMFtrack\")\n",
    "from amftrack.util.sys import storage_path\n",
    "from amftrack.util.geometry import generate_index_along_sequence\n",
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    compute_edge_width_profile,\n",
    "    extract_section_profiles_for_edge,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    Node,\n",
    "    Edge,\n",
    ")\n",
    "from amftrack.util.sys import get_current_folders, update_plate_info, test_path\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    plot_edge_width,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45275fb-fbb1-4cd1-95e7-0a38cc5113ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test\"\n",
    "directory = storage_path+\"/\"\n",
    "plate_name = \"20221116_0311\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34a6f2e-b677-4f05-98b0-739d710209bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bdd0d90dbe4e57b046465d65673602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "analysed:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipausers/lin/Desktop/AMF/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.folders[\"datetime\"] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-16 03:11:00\n"
     ]
    }
   ],
   "source": [
    "update_plate_info(directory)\n",
    "folder_df = get_current_folders(directory)\n",
    "select = folder_df[folder_df[\"Plate\"] == \"705\"]\n",
    "exp = Experiment(directory)\n",
    "exp.load(select, suffix=\"\")\n",
    "exp.load_tile_information(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b91833-10c1-46c1-b895-cfb93cad280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_fun = lambda edge: compute_edge_width_profile(\n",
    "    exp, 0, edge, resolution=4, offset=5, target_length=100\n",
    ")\n",
    "f = lambda n: generate_index_along_sequence(n, resolution=4, offset=5)\n",
    "f_profiles = lambda edge: extract_section_profiles_for_edge(\n",
    "    exp, 0, edge, resolution=5, offset=4, step=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71341aa0-fca4-400b-8f92-21ec3066b095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find_image_indexes() missing 2 required positional arguments: 'DIM_X' and 'DIM_Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m edges:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(edge\u001b[38;5;241m.\u001b[39mpixel_list(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m         widths \u001b[38;5;241m=\u001b[39m \u001b[43mwidth_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         medians[edge] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(widths)\n",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(edge)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m width_fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m edge: \u001b[43mcompute_edge_width_profile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m n: generate_index_along_sequence(n, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m f_profiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m edge: extract_section_profiles_for_edge(\n\u001b[1;32m      6\u001b[0m     exp, \u001b[38;5;241m0\u001b[39m, edge, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/AMF/AMFtrack/amftrack/pipeline/functions/image_processing/extract_width_fun.py:53\u001b[0m, in \u001b[0;36mcompute_edge_width_profile\u001b[0;34m(exp, t, edge, resolution, offset, step, target_length)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_edge_width_profile\u001b[39m(\n\u001b[1;32m     44\u001b[0m     exp: Experiment,\n\u001b[1;32m     45\u001b[0m     t: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     target_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m,\n\u001b[1;32m     51\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m     profile, _, __ \u001b[38;5;241m=\u001b[39m \u001b[43mextract_section_profiles_for_edge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     predicted_widths \u001b[38;5;241m=\u001b[39m MODEL\u001b[38;5;241m.\u001b[39mpredict(profile)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_widths\n",
      "File \u001b[0;32m~/Desktop/AMF/AMFtrack/amftrack/pipeline/functions/image_processing/extract_width_fun.py:252\u001b[0m, in \u001b[0;36mextract_section_profiles_for_edge\u001b[0;34m(exp, t, edge, resolution, offset, step, target_length)\u001b[0m\n\u001b[1;32m    250\u001b[0m image_coord_list \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mget_image_coords(t)\n\u001b[1;32m    251\u001b[0m DIM_X, DIM_Y \u001b[38;5;241m=\u001b[39m get_dimX_dimY(exp)\n\u001b[0;32m--> 252\u001b[0m image_indexes, new_section_coord_list \u001b[38;5;241m=\u001b[39m \u001b[43mfind_source_images_filtered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_of_segments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_coord_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDIM_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDIM_Y\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m images \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(image_indexes):\n",
      "File \u001b[0;32m~/Desktop/AMF/AMFtrack/amftrack/pipeline/functions/image_processing/extract_width_fun.py:197\u001b[0m, in \u001b[0;36mfind_source_images_filtered\u001b[0;34m(section_coord_list, image_coord_list, DIM_X, DIM_Y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    189\u001b[0m     is_in_image(\n\u001b[1;32m    190\u001b[0m         current_image[\u001b[38;5;241m0\u001b[39m], current_image[\u001b[38;5;241m1\u001b[39m], point1[\u001b[38;5;241m0\u001b[39m], point1[\u001b[38;5;241m1\u001b[39m], DIM_X, DIM_Y\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m ):\n\u001b[1;32m    196\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew image needed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 197\u001b[0m     images1 \u001b[38;5;241m=\u001b[39m \u001b[43mfind_image_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_coord_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     images2 \u001b[38;5;241m=\u001b[39m find_image_indexes(image_coord_list, point2[\u001b[38;5;241m0\u001b[39m], point2[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    199\u001b[0m     possible_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(images1) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(images2))\n",
      "\u001b[0;31mTypeError\u001b[0m: find_image_indexes() missing 2 required positional arguments: 'DIM_X' and 'DIM_Y'"
     ]
    }
   ],
   "source": [
    "edges = get_all_edges(exp, 0)\n",
    "medians = {}\n",
    "mean = {}\n",
    "for edge in edges:\n",
    "    if len(edge.pixel_list(0)) > 100:\n",
    "        widths = width_fun(edge)\n",
    "        medians[edge] = np.median(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03841009-404d-47f6-9a2a-8d8049e7cdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_section_profiles_for_edge(\n",
    "    exp: Experiment,\n",
    "    t: int,\n",
    "    edge: Edge,\n",
    "    resolution=5,\n",
    "    offset=4,\n",
    "    step=3,\n",
    "    target_length=120,\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Main function to extract section profiles of an edge.\n",
    "    Given an Edge of Experiment at timestep t, returns a np array\n",
    "    of dimension (target_length, m) where m is the number of section\n",
    "    taken on the hypha.\n",
    "    :param resolution: distance between two measure points along the hypha\n",
    "    :param offset: distance at the end and the start where no point is taken\n",
    "    :param step: step in pixel to compute the tangent to the hypha\n",
    "    :target_length: length of the section extracted in pixels\n",
    "    :return: np.array of sections, list of segments in TIMESTEP referential\n",
    "    \"\"\"\n",
    "    pixel_list = edge.pixel_list(t)\n",
    "    offset = max(\n",
    "        offset, step\n",
    "    )  # avoiding index out of range at start and end of pixel_list\n",
    "    pixel_list_ts = [exp.general_to_timestep(point, t) for point in pixel_list]\n",
    "    pixel_indexes = generate_pivot_indexes(\n",
    "        len(pixel_list), resolution=resolution, offset=offset\n",
    "    )\n",
    "    list_of_segments = compute_section_coordinates(\n",
    "        pixel_list_ts, pixel_indexes, step=step, target_length=target_length + 1\n",
    "    )  # target_length + 1 to be sure to have length all superior to target_length when cropping\n",
    "    # TODO (FK): is a +1 enough?\n",
    "    image_coord_list = exp.get_image_coords(t)\n",
    "    image_indexes, new_section_coord_list = find_source_images_filtered(\n",
    "        list_of_segments, image_coord_list\n",
    "    )\n",
    "    images = {}\n",
    "    for im_index in set(image_indexes):\n",
    "        images[im_index] = exp.get_image(t, im_index)\n",
    "    l = []\n",
    "    for i, sect in enumerate(new_section_coord_list):\n",
    "        im = images[image_indexes[i]]\n",
    "        point1 = np.array([sect[0][0], sect[0][1]])\n",
    "        point2 = np.array([sect[1][0], sect[1][1]])\n",
    "        profile = profile_line(im, point1, point2, mode=\"constant\")[:target_length]\n",
    "        profile = profile.reshape((1, len(profile)))\n",
    "        # TODO(FK): Add thickness of the profile here\n",
    "        l.append(profile)\n",
    "    return np.concatenate(l, axis=0), list_of_segments, new_section_coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd72ece-3c7e-4471-ba51-5d4c0845be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pivot_indexes(n: int, resolution=3, offset=5):\n",
    "    \"\"\"\n",
    "    From the length of the pixel list, determine which pixel will be chosen to compute width\n",
    "    :param n: length of the list of pixels\n",
    "    :param resolution: step between two chosen points\n",
    "    :param offset: offset at the begining and at the end where no points will be selected\n",
    "    \"\"\"\n",
    "    return generate_index_along_sequence(n, resolution, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa1fd606-d269-496a-8e57-4dcdc580f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.util.geometry import get_section_segment\n",
    "from amftrack.util.image_analysis import is_in_image\n",
    "def compute_section_coordinates(\n",
    "    pixel_list, pivot_indexes, step: int, target_length=120\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the coordinates of each segment section where the width will be computed\n",
    "    :param pivot_indexes: list of indexes in the pixel_list\n",
    "    :param step: this determine which neibooring points to use for computing the tangent\n",
    "    :param target_length: the approximate target_length that we want for the segment\n",
    "    WARNING: taget_length is not exact as the coordinates are ints\n",
    "    NB: the coordinates are all in the general referential\n",
    "    \"\"\"\n",
    "    # TODO(FK): handle case where the step is bigger than the offset, raise error instead of logging\n",
    "    if step > pivot_indexes[0]:\n",
    "        logger.error(\"The step is bigger than the offset. Offset should be raised\")\n",
    "    list_of_segments = []\n",
    "    for i in pivot_indexes:\n",
    "        pivot = pixel_list[i]\n",
    "        before = pixel_list[i - step]\n",
    "        after = pixel_list[i + step]\n",
    "        orientation = np.array(before) - np.array(after)\n",
    "        list_of_segments.append(get_section_segment(orientation, pivot, target_length))\n",
    "    return list_of_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72238c01-47d0-4f24-921c-e17d55ff0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_source_images_filtered(\n",
    "    section_coord_list, image_coord_list):\n",
    "    \"\"\"\n",
    "    For each segment in section_coord_list, determine the index of an\n",
    "    image in `image_coord_list` which contains the segment.\n",
    "    If no image contains fully the segment, the segment is removed.\n",
    "    :return:\n",
    "    - List of image indexes for each section\n",
    "    - List of coordinates of the segment in their respective image\n",
    "    NB: This implementation suppose that the section are close to one another\n",
    "    and that there are often in the same image as the previous one\n",
    "    \"\"\"\n",
    "    image_indexes = []  # image index for each segment\n",
    "    new_section_coord_list = []  # segment list filtered and converted to the image ref\n",
    "\n",
    "    current_image = [np.inf, np.inf]\n",
    "    current_index = 0\n",
    "    for sec in section_coord_list:\n",
    "        (point1, point2) = sec\n",
    "        if not (\n",
    "            is_in_image(current_image[0], current_image[1], point1[0], point1[1])\n",
    "            and is_in_image(current_image[0], current_image[1], point2[0], point2[1])\n",
    "        ):\n",
    "            logging.debug(\"New image needed\")\n",
    "            images1 = find_image_indexes(image_coord_list, point1[0], point1[1])\n",
    "            images2 = find_image_indexes(image_coord_list, point2[0], point2[1])\n",
    "            possible_choices = list(set(images1) & set(images2))\n",
    "            if possible_choices == []:\n",
    "                logger.debug(\n",
    "                    \"This section is not contained in a single original image. Skipping..\"\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                index = possible_choices[0]  # NB(FK): we choose randomly\n",
    "                current_index = index\n",
    "                current_image = image_coord_list[index]\n",
    "        # Adding the new point and its image index\n",
    "        image_indexes.append(current_index)\n",
    "        new_sec = [\n",
    "            [point[0] - current_image[0], point[1] - current_image[1]] for point in sec\n",
    "        ]\n",
    "        new_section_coord_list.append(new_sec)\n",
    "    return image_indexes, new_section_coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e75b7511-791c-4c44-a9a0-a70b7c5191e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "is_in_image() missing 2 required positional arguments: 'DIM_X' and 'DIM_Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_section_profiles_for_edge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 34\u001b[0m, in \u001b[0;36mextract_section_profiles_for_edge\u001b[0;34m(exp, t, edge, resolution, offset, step, target_length)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# TODO (FK): is a +1 enough?\u001b[39;00m\n\u001b[1;32m     33\u001b[0m image_coord_list \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mget_image_coords(t)\n\u001b[0;32m---> 34\u001b[0m image_indexes, new_section_coord_list \u001b[38;5;241m=\u001b[39m \u001b[43mfind_source_images_filtered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_of_segments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_coord_list\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m images \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(image_indexes):\n",
      "Cell \u001b[0;32mIn [27], line 21\u001b[0m, in \u001b[0;36mfind_source_images_filtered\u001b[0;34m(section_coord_list, image_coord_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sec \u001b[38;5;129;01min\u001b[39;00m section_coord_list:\n\u001b[1;32m     19\u001b[0m     (point1, point2) \u001b[38;5;241m=\u001b[39m sec\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m---> 21\u001b[0m         \u001b[43mis_in_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_image\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_image\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_in_image(current_image[\u001b[38;5;241m0\u001b[39m], current_image[\u001b[38;5;241m1\u001b[39m], point2[\u001b[38;5;241m0\u001b[39m], point2[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     23\u001b[0m     ):\n\u001b[1;32m     24\u001b[0m         logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew image needed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m         images1 \u001b[38;5;241m=\u001b[39m find_image_indexes(image_coord_list, point1[\u001b[38;5;241m0\u001b[39m], point1[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: is_in_image() missing 2 required positional arguments: 'DIM_X' and 'DIM_Y'"
     ]
    }
   ],
   "source": [
    "extract_section_profiles_for_edge(\n",
    "    exp,\n",
    "    0,\n",
    "    edge = edge,\n",
    "    resolution=5,\n",
    "    offset=4,\n",
    "    step=3,\n",
    "    target_length=120,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76665159-9b96-462d-a3ee-0d6ddfbb58df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
